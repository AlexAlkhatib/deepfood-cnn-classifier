# **Deep Food â€” Classification de 101 CatÃ©gories Alimentaires avec CNN, Transfert dâ€™Apprentissage & PrÃ©cision Mixte**

Ce projet a pour objectif de **classer plus de 100 catÃ©gories dâ€™aliments** Ã  partir du dataset *Food101* en utilisant un modÃ¨le CNN moderne optimisÃ© via :

* **Transfert dâ€™apprentissage (EfficientNetV2B0)**
* **EntraÃ®nement en prÃ©cision mixte (float16/float32)**
* **GPU acceleration (NVIDIA RTX)**
* **Pipeline TensorFlow Dataset performant**
* **Callbacks TensorBoard & ModelCheckpoint**

Il sâ€™agit dâ€™un projet **personnel** visant Ã  dÃ©velopper de solides compÃ©tences en vision par ordinateur, deep learning et optimisation de modÃ¨les.


## ğŸ¯ **Objectifs du projet**

* Utiliser le dataset **Food101** avec TensorFlow Datasets
* PrÃ©traiter efficacement + normaliser + redimensionner toutes les images
* Construire un modÃ¨le CNN basÃ© sur **EfficientNetV2B0** prÃ©-entraÃ®nÃ©
* Activer la **prÃ©cision mixte** pour un entraÃ®nement plus rapide
* EntraÃ®ner et valider le modÃ¨le sur GPU
* Sauvegarder les meilleurs poids via *ModelCheckpoint*
* Visualiser et analyser les courbes dâ€™apprentissage
* Obtenir une **prÃ©cision Ã©levÃ©e** malgrÃ© +100 classes


## ğŸ§° **Stack Technique**

* **Python 3**
* **TensorFlow 2 / Keras**
* **TensorFlow Datasets (TFDS)**
* **GPU NVIDIA (RTx)** + CUDA + cuDNN
* **EfficientNetV2B0** (pretrained ImageNet)
* **Mixed Precision Training**
* **Callbacks TensorBoard & Checkpoints**
* **Matplotlib**


## ğŸ“¦ **Dataset : Food101**

Dataset officiel :
101 catÃ©gories dâ€™aliments

* 1000 images par classe
  Images non normalisÃ©es (0â€“255), tailles variables.

Chargement via TFDS :

```python
(train_data, test_data), ds_info = tfds.load(
    name="food101",
    split=["train", "validation"],
    shuffle_files=True,
    as_supervised=True,
    with_info=True
)
```

Nombre de classes :

```python
len(class_names)  # 101
```


## ğŸ§¹ **PrÃ©traitement & Pipeline TensorFlow**

### ProblÃ¨mes dans les donnÃ©es :

* images tailles variables
* pixels entiers (uint8)
* besoin de normalisation

### Ã‰tapes de prÃ©traitement :

* **Redimensionnement** Ã  224Ã—224
* **Cast en float32**
* **Batching + Prefetching GPU**

```python
def preprocess_img(image, label, img_shape=224):
    image = tf.image.resize(image, [img_shape, img_shape])
    return tf.cast(image, tf.float32), label
```

Pipeline optimisÃ© :

```python
train_data = train_data.map(...).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)
test_data  = test_data.map(...).batch(32).prefetch(tf.data.AUTOTUNE)
```


## âš¡ **AccÃ©lÃ©ration : EntraÃ®nement en prÃ©cision mixte**

Active :

```python
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy("mixed_float16")
```

Avantages :

* EntraÃ®nement **2x plus rapide**
* RÃ©duction de l'utilisation mÃ©moire GPU
* BÃ©nÃ©ficiel pour EfficientNet


## ğŸ§  **ModÃ¨le CNN â€” EfficientNetV2B0 (Transfert dâ€™Apprentissage)**

Base :

```python
base_model = tf.keras.applications.EfficientNetV2B0(
    include_top=False
)
base_model.trainable = False  # Extraction de features
```

Architecture :

* Input Layer
* EfficientNetV2B0 gelÃ©
* GlobalAveragePooling2D
* Dense(101)
* Softmax **float32** (pour Ã©viter la perte de prÃ©cision mixte)

Compilation :

```python
model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=tf.keras.optimizers.Adam(),
    metrics=["accuracy"]
)
```


## ğŸ”„ **Callbacks : TensorBoard & Model Checkpoints**

### TensorBoard

```python
create_tensorboard_callback()
```

### Checkpoints

```python
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    "model_checkpoints/cp.weights.h5",
    monitor="val_acc",
    save_best_only=True,
    save_weights_only=True
)
```


## ğŸ‹ï¸ **EntraÃ®nement**

ModÃ¨le exÃ©cutÃ© sur GPU NVIDIA RTX 2060 :

```bash
!nvidia-smi -L
```

Training :

```python
history = model.fit(train_data,
                    validation_data=test_data,
                    epochs=EPOCHS,
                    callbacks=[tensorboard, model_checkpoint])
```


## ğŸ“ˆ **Ã‰valuation & Visualisation**

Les courbes dâ€™apprentissage (loss/accuracy) sont affichÃ©es via :

```python
plot_loss_curves(history)
```

PossibilitÃ© de comparer plusieurs phases dâ€™entraÃ®nement :

```python
compare_historys(...)
```


## ğŸ§  **CompÃ©tences dÃ©montrÃ©es**

âœ” Vision par ordinateur avancÃ©e
âœ” CNN avec TensorFlow/Keras
âœ” Transfert dâ€™apprentissage EfficientNet
âœ” Optimisation GPU + prÃ©cision mixte
âœ” Manipulation TFDS & pipelines haute performance
âœ” PrÃ©traitement dâ€™images deep learning
âœ” Callbacks professionnels (TensorBoard, checkpointing)
âœ” Classification multi-classes (101 catÃ©gories)
âœ” Programmation orientÃ©e performance (prefetch, AUTOTUNE)


## ğŸš€ **Pistes dâ€™amÃ©lioration**

* Ajout dâ€™un scheduler (ReduceLROnPlateau)
* Augmentation de donnÃ©es (tf.image)
* Test dâ€™EfficientNetV2M ou V2L
* Export en format TF-Lite pour mobile
* DÃ©ploiement API (FastAPI) + front-end


## ğŸ‘¤ **Ã€ propos**

Projet rÃ©alisÃ© par **Alex Alkhatib**, passionnÃ© par la vision par ordinateur et les modÃ¨les deep learning modernes.


## ğŸ“„ Licence
MIT License
Copyright (c) 2025 Alex Alkhatib

Souhaites-tu lâ€™un de ces bonus ?
